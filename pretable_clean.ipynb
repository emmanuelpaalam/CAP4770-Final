{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092ba004",
   "metadata": {},
   "source": [
    "# Pre-MySQL Cleaning Notebook\n",
    "### Author: Emmanuel Paalam\n",
    "### Date: 07/16/2025\n",
    "\n",
    "This notebook was created to perform the necessary cleanings on the dimensionally dense dataset from the Educational Longitudinal Study of 2002 (ELS:2002) prior to MySQL table creation and insertion for a CAP4770 group project.\n",
    "\n",
    "The decided use for the data by the group (author, Charles Smith, Everett Williams) was to examine the survey's recorded participant data from the baseline year of the study to its first follow up, thus lasting from 10th grade to 12th grade for participants. At this point, participants should be either graduating or have dropped out of school at some point: our goal is to assess the data collected in this two-year period and characterize dropouts and non-dropouts accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12746a63",
   "metadata": {},
   "source": [
    "## Load in CSV data\n",
    "\n",
    "Data downloadable from https://nces.ed.gov/datalab/onlinecodebook/session/codebook/d27ac790-3fdf-452d-ba74-e33e786024da.\n",
    "\n",
    "This notebook assumes that it exists in a directory in which it shares a parent directory with the data, the latter located in a neighboring child folder called *data*. Pathways should be changed as needed for alternate project implementation - all that matters is that the appropiate file is used for cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4011cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epaal\\AppData\\Local\\Temp\\ipykernel_27076\\2311857552.py:2: DtypeWarning: Columns (1222) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/els_02_12_byf3pststu_v1_0.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16197, 4012)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/els_02_12_byf3pststu_v1_0.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed12018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9078df35",
   "metadata": {},
   "source": [
    "At this point, it should be clear why a pre-MySQL cleaning is needed: there are far too many columns (attributes) in the raw data, many of which are not needed by us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718244e7",
   "metadata": {},
   "source": [
    "## Column + Row Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302ee1e",
   "metadata": {},
   "source": [
    "As a note, there are actually a lot of missing values in the data - any non-responses per student will be recorded as a negative value (e.g.: -9 for \"Not Applicable\", -8 for \"Refused to answer\", -7 for \"Item legitimate skip\"), and there are many rows with these. However, we should decide what to do with these \"missings\" when needed - this can still be valuable information too. EDA, for example, may benefit from including these missings \n",
    "\n",
    "Meanwhile, irrelevant data (anything not from the baseline year or first follow-up) make up almost half of the dataset. Let's see how much of our dataset is truly needed with this in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a692f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(regex='^(?!F2|F1T|F3)')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72574ff",
   "metadata": {},
   "source": [
    "Still, a lot of the remaining variables include non-informative columns (e.g.: ID variables, estimated variables like BYTXMIRR or BYNELS2M, comparative variables like BYPISAME or BYPISARE).\n",
    "\n",
    "The goal of this pre-table clean is to establish a solid collection of academic and non-academic attributes on all students, so I, the author, will now manually extract a number of columns that I deem useful for our project based on found literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e047f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16197, 41)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected = pd.DataFrame()\n",
    "\n",
    "selected_columns = [\n",
    "    # === Core Identifiers & Target Variable ===\n",
    "    \"STU_ID\",          # Unique student identifier, essential for merging data\n",
    "    \"F1EVERDO\",        # Target Variable: 1st follow-up, student ever dropped out (0=No, 1=Yes)\n",
    "\n",
    "    # === Academic Background & Performance ===\n",
    "    \"BYTXRSTD\",        # Standardized test score, reading (continuous)\n",
    "    \"BYTXMSTD\",        # Standardized test score, math (continuous)\n",
    "    \"BYSCHPRG\",        # Student's high school program (e.g., academic, general, vocational)\n",
    "    \"BYGRDRPT\",        # Ever repeated a grade from 1st to 9th\n",
    "    \"BYS33A\",          # Ever in an Advanced Placement (AP) program\n",
    "    \"BYS33D\",          # Ever in a remedial English class\n",
    "    \"BYS33E\",          # Ever in a remedial Math class\n",
    "    \"BYS33H\",          # Ever in a dropout prevention program\n",
    "\n",
    "    # === Student Behaviors & Engagement ===\n",
    "    \"BYHMWRK\",         # Hours spent on homework per week, base year\n",
    "    \"BYXTRACU\",        # Participation in extracurricular activities\n",
    "    \"BYS24A\",          # How many times late for school, base year\n",
    "    \"BYS24B\",          # How many times cut/skipped class, base year\n",
    "    \"BYS24C\",          # How many times absent from school, base year\n",
    "    \"BYS38C\",          # Goes to class without homework done, base year\n",
    "    \"F1S31\",           # In-school student: hours/week on homework, 1st follow-up\n",
    "\n",
    "    # === Psychosocial & Attitudinal Factors ===\n",
    "    \"BYSTEXP\",         # Student's educational expectations, base year\n",
    "    \"F1STEXP\",         # Student's educational expectations, 1st follow-up\n",
    "    \"BYSES1\",          # Socioeconomic status (SES) composite 1, base year (continuous)\n",
    "    \"BYS89A\",          # Self-concept: confident can do excellent on math tests\n",
    "    \"BYS89I\",          # Self-concept: confident can do excellent on English assignments\n",
    "    \"BYS89E\",          # Locus of control: 'When I learn something hard, I can learn it'\n",
    "    \"BYS89N\",          # Locus of control: 'If I decide not to get bad grades, I can do it'\n",
    "    \"BYS20A\",          # School climate: students get along with teachers\n",
    "    \"BYS20B\",          # School climate: there is real school spirit\n",
    "    \"BYS20J\",          # School climate: student doesn't feel safe at this school\n",
    "    \"BYS20K\",          # School climate: disruptions get in way of learning\n",
    "\n",
    "    # === Peer Group Influence ===\n",
    "    \"BYS90B\",          # Peer group attitudes: importance of studying\n",
    "    \"BYS90D\",          # Peer group attitudes: importance of getting good grades\n",
    "    \"BYS90F\",          # Peer group attitudes: importance of finishing high school\n",
    "    \"BYS90L\",          # Peer group attitudes: importance of getting together on weekends\n",
    "    \"BYS91\",           # Number of close friends who dropped out\n",
    "\n",
    "    # === Family, Home & Financial Factors ===\n",
    "    \"BYINCOME\",        # Total family income for 2001\n",
    "    \"F1MOTHED\",        # Mother's highest level of education, 1st follow-up\n",
    "    \"F1FATHED\",        # Father's highest level of education, 1st follow-up\n",
    "    \"F1OCCUM\",         # Mother's occupation, 1st follow-up\n",
    "    \"F1OCCUF\",         # Father's occupation, 1st follow-up\n",
    "    \"BYFCOMP\",         # Family composition, base year\n",
    "    \"F1FCOMP\",         # Family composition, 1st follow-up\n",
    "    \"BYHOMLNG\",        # Language spoken at home other than English\n",
    "]\n",
    "\n",
    "for col in selected_columns:\n",
    "    df_selected[col] = df[col]\n",
    "\n",
    "df_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5472b",
   "metadata": {},
   "source": [
    "## Table Creation\n",
    "\n",
    "This portion of the notebook assumes MySQL is installed and a local instance of the server is prepared, plus that all of the required dependencies in the following cell are available.\n",
    "\n",
    "MySQL has an installer that can be downloaded here: https://dev.mysql.com/downloads/installer/. Once you have *Workbench* and *Server* installed locally, **enter your own admin password into *db_config*.** The input host value allows create_engine to loop back to your computer when searching for the MySQL server to connect to - and your computer will have a local MySQL instance at this point if *Server* was installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# --- 1. Database Connection Details ---\n",
    "db_config = {\n",
    "    'user': 'root',\n",
    "    'password': 'YOUR_ROOT_PASSWORD_HERE', # Replace with your password\n",
    "    'host': '127.0.0.1',\n",
    "    'raise_on_warnings': True\n",
    "}\n",
    "\n",
    "db_name = 'els2002_selected_columns' # The name of the database you want to use\n",
    "\n",
    "\n",
    "# --- 2. Create the Database (if it doesn't exist) ---\n",
    "try:\n",
    "    # Connect to the MySQL server\n",
    "    cnx = mysql.connector.connect(**db_config)\n",
    "    cursor = cnx.cursor()\n",
    "    \n",
    "    # Create the database\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "    print(f\"Database '{db_name}' is ready.\")\n",
    "    \n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Failed to create database: {err}\")\n",
    "\n",
    "\n",
    "# --- 3. Load DataFrame into a SQL Table ---\n",
    "try:\n",
    "    # Create a SQLAlchemy engine to talk to the database\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_name}\")\n",
    "    \n",
    "    table_name = 'els_2002_data' # Choose a name for your table\n",
    "    \n",
    "    # Use pandas to_sql to load the data\n",
    "    # 'if_exists='replace'' will overwrite the table if it already exists.\n",
    "    # Use 'append' if you want to add data, or 'fail' to prevent overwriting.\n",
    "    df_selected.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(f\"DataFrame successfully loaded into table '{table_name}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load data into MySQL: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FOR CAP4770 FINAL",
   "language": "python",
   "name": "proj_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
